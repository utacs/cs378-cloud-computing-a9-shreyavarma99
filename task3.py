from pyspark import SparkConf,SparkContext
from pyspark.streaming import StreamingContext
import sys
from operator import add
import json

import re 

# Emoji regex generated by ChatGPT
emoji_pattern = re.compile(
    "[" 
    u"\U0001F600-\U0001F64F"  # emoticons
    u"\U0001F300-\U0001F5FF"  # symbols & pictographs
    u"\U0001F680-\U0001F6FF"  # transport & map
    u"\U0001F1E0-\U0001F1FF"  # flags
    u"\U0001F900-\U0001F9FF"  # supplemental symbols
    u"\U00002600-\U000026FF"  # misc symbols
    "]+", flags=re.UNICODE
)

def contains_emoji(text):
    return bool(emoji_pattern.search(text))

def classify_record(tweet):
    tweet = tweet.lower()

    health_words = [
        "doctor", "patient", "disease", "health", "cancer", "medical", "emergency",
        "medicine", "hospital", "clinical", "nutrition", "deficiency", "allergy",
        "immunity", "immunization", "virus", "antibiotic", "chromosome", "flu"
    ]
    
    not_health_words = [
        "pain in the ass", "fever dream", "OMG", "cabin fever", 
        "heartache", "love sick", "sick of this", "sick and tired", "fire",
        "banger", "song", "club", "party", "vibe", "sheesh", "morbius fever", 
        "sick leave", "gamers"
    ]

    for phrase in not_health_words:
        if phrase in tweet:
            return False
        
    if contains_emoji(tweet):
        return False
    
    return any(word in tweet for word in health_words)

conf = SparkConf()
conf.setAppName("Task3")

sc = SparkContext(conf=conf)
sc.setLogLevel("FATAL")

ssc = StreamingContext(sc, 5)
ssc.checkpoint("checkpoint_TwitterApp")

dataStream = ssc.socketTextStream("localhost", 9009)

windowedDataStream = dataStream.window(300, 5)

def compute_percentage(x):
    health_count = x[0]
    total = x[1]
    if total != 0:
        percentage = (health_count / total) * 100
        return f"(Health tweet percentage: {percentage:.2f}%)"
    else:
        return "(Health tweet percentage: 0.00%)"

keywords = ["fever", "ache", "pain", "sick"]
kw = sc.broadcast(keywords)

task3 = windowedDataStream\
.filter(lambda x: any(word in x.lower() for word in kw.value))\
.map(lambda x: (1 if classify_record(x) else 0, 1))\
.reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\
.map(compute_percentage)\

task3.pprint(5)

# Start streaming
ssc.start()
ssc.awaitTermination()
